# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
import streamlit as st
from openai import AzureOpenAI

# í™˜ê²½ë³€ìˆ˜ ë˜ëŠ” ì§ì ‘ ì…ë ¥ìœ¼ë¡œ ì„¤ì •ê°’ ê°€ì ¸ì˜¤ê¸°
azure_endpoint = "https://internal-apigw-kr.hmg-corp.io/hchat-in/api/v2/01K6ET0Y7FMK2PN72HDMZ4P9W6"
api_key = "OYlOck5vnTLYUF7iE2hmeZlK2Z84bR0gLsSwC5em4zyDIpBSvzQXChRDaBopvWw"


# AzureOpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = AzureOpenAI(
    azure_endpoint=azure_endpoint,
    api_key=api_key,
    api_version="2024-10-21"
)

# Streamlit ì•± ì œëª©
st.title("ğŸ’¬ LLM ì±—ë´‡ ë§Œë“¤ê¸°")

# ----------------
# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
# ----------------
if "history" not in st.session_state:
    st.session_state["history"] = [
        {"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! ê¶ê¸ˆí•œ ì ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."}
    ]
if "email_mode" not in st.session_state:
    st.session_state["email_mode"] = False

# ----------------
# ì´ë©”ì¼ëª¨ë“œ on/off ë²„íŠ¼ UI ë° ì•ˆë‚´ë¬¸
# ----------------
with st.sidebar:
    # ì´ë©”ì¼ ëª¨ë“œ ì „í™˜ ë²„íŠ¼
    if st.session_state["email_mode"]:
        if st.button("ì´ë©”ì¼ ëª¨ë“œ ì¢…ë£Œ", use_container_width=True):
            st.session_state["email_mode"] = False
    else:
        if st.button("ì´ë©”ì¼ ëª¨ë“œ ì‹œì‘", use_container_width=True):
            st.session_state["email_mode"] = True
    
    st.markdown("---")
    st.markdown(
        "â„¹ï¸ **ì´ë©”ì¼ ëª¨ë“œ ì•ˆë‚´**\n\n"
        "- ë²„íŠ¼ì„ í´ë¦­í•˜ë©´, ì…ë ¥ ë‚´ìš©ì„ ë¹„ì¦ˆë‹ˆìŠ¤ ì´ë©”ì¼ í˜•íƒœë¡œ ì‘ì„±í•´ì¤ë‹ˆë‹¤.\n"
        "- ì¼ë°˜ ì±—ë´‡ ëª¨ë“œë¡œ ì–¸ì œë“  ëŒì•„ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    )

# ì´ë©”ì¼ ëª¨ë“œ í™œì„±í™” ì‹œ ìƒë‹¨ ì•ˆë‚´ ì¶œë ¥
if st.session_state["email_mode"]:
    st.info("ğŸ“§ **ì´ë©”ì¼ ëª¨ë“œê°€ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤**\n- ì´ì œ ì±—ë´‡ì€ ëª¨ë“  ë‹µë³€ì„ ê³µì‹ì ì¸ ì—…ë¬´ìš© ì´ë©”ì¼ë¡œ ì‘ì„±í•©ë‹ˆë‹¤.")




# ----------------
# ëŒ€í™” ê¸°ë¡ ì¶œë ¥ í•¨ìˆ˜
# ----------------
def display_chat():
    for msg in st.session_state["history"]:
        if msg["role"] == "user":
            st.chat_message("user").markdown(msg["content"])
        else:
            st.chat_message("assistant").markdown(msg["content"])

display_chat()

# ----------------
# ì…ë ¥ì°½
# ----------------
user_input = st.chat_input(
    "ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”."
)

# ----------------
# LLM ì‘ë‹µ ìƒì„± í•¨ìˆ˜
# ----------------
def get_llm_response(messages, email_mode=False):
    # ì´ë©”ì¼ ëª¨ë“œì´ë©´ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì¶”ê°€
    if email_mode:
        system_prompt = {
            "role": "system",
            "content": (
                "ì•ìœ¼ë¡œ ìš”ì²­ë°›ëŠ” ëª¨ë“  ë‚´ìš©ì„, ëª©ì ì— ë§ëŠ” ê³µì‹ì ì´ê³  ê°„ê²°í•œ í•œêµ­ì–´ ì—…ë¬´ìš© ì´ë©”ì¼ë¡œ ì‘ì„±í•˜ì„¸ìš”. "
                "ì´ë©”ì¼ ì„œì‹(ì¸ì‚¬ë§, ë§ˆë¬´ë¦¬, ì„œëª… ë“±)ë„ ë„£ì–´ì£¼ê³ , ìš”êµ¬/ì§ˆë¬¸ì´ ë¶ˆë¶„ëª…í•˜ë©´ ì¶”ê°€ë¡œ ëª…í™•í•œ ì •ë³´ë¥¼ ì§ˆë¬¸í•˜ì„¸ìš”."
            )
        }
        # í”„ë¡¬í”„íŠ¸ ìµœìƒë‹¨ì— system í”„ë¡¬í”„íŠ¸ ë°°ì¹˜
        prompt_messages = [system_prompt] + messages
    else:
        prompt_messages = messages
        
    try:
        response = client.chat.completions.create(
            model="gpt-4.1",
            messages=prompt_messages
        )
        answer = response.choices[0].message.content
    except Exception as e:
        answer = f"âš ï¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    return answer

# ----------------
# ì…ë ¥ ì²˜ë¦¬ ë° ì±—ë´‡ ì‘ë‹µ
# ----------------
if user_input:
    # ëŒ€í™” ê¸°ë¡ì— ì‚¬ìš©ì ì…ë ¥ ì¶”ê°€
    st.session_state["history"].append({"role": "user", "content": user_input})
    display_chat()

    # LLM ì‘ë‹µ ìƒì„± (ëª¨ë“œì— ë”°ë¼ í”„ë¡¬í”„íŠ¸ ë‹¤ë¥´ê²Œ)
    bot_message = get_llm_response(
        st.session_state["history"],
        email_mode=st.session_state["email_mode"]
    )

    # ëŒ€í™” ê¸°ë¡ì— assistant ë‹µë³€ ì¶”ê°€
    st.session_state["history"].append(
        {"role": "assistant", "content": bot_message}
    )

display_chat()
